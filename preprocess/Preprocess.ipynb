{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import string\n",
    "from collections import Counter \n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "data = pd.read_csv('data/GOOGLESCRAPERESULT.csv')\n",
    "det = data['DETAILS_MEDS'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDate(str):\n",
    "    temp = re.sub('^[0-9]{1,2}[ \\w]{4}[ 0-9]{5}', ' ', str)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitText(s):\n",
    "    c = s.count('...')\n",
    "    return s.split(\"...\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for item in det:\n",
    "    res.append(splitText(item))\n",
    "    \n",
    "res = [item for sublist in res for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePunct(s):\n",
    "    symb = [';', '?', '!', '&', '\\n', '\\xa0', \"Â·\", '|', '(', ')', '@', '/', ':', ' x ', ' X ', '+']\n",
    "    for sy in symb:\n",
    "        s = s.replace(sy, \" \")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonASCII(s):\n",
    "    printable = set(string.printable)\n",
    "    return ''.join(filter(lambda x: x in printable, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitMeasure(s):\n",
    "    temp = re.sub('([0-9]mg|[0-9]Mg|[0-9]MG|[0-9]ML|[0-9]Ml|[0-9]ml)', r' \\1', re.sub('(mg+|Mg+|Ml+|ml+|MG+|ML+)', r' \\1', s)).split()\n",
    "    res = ' '.join(temp).replace('mg.', 'mg. ')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if has lot of periods replace with comma. (in case confused with decimal)\n",
    "def find(s):\n",
    "    temp = s.count('.')\n",
    "    return temp\n",
    "\n",
    "def replacePeriod(s):\n",
    "    if find(s) > 2:\n",
    "        s = s.replace('.', ',')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSentence(s):\n",
    "    sent_text = nltk.sent_tokenize(s)\n",
    "    return sent_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess1(s):\n",
    "    temp = splitSentence(replacePeriod(splitMeasure(nonASCII(removePunct(removeDate(s))))))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = []\n",
    "for item in res:\n",
    "    res1.append(preprocess1(item))\n",
    "flat_list = [item for sublist in res1 for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanPunct(s):\n",
    "    '''\n",
    "    remove punct , and . except on decimal\n",
    "    '''\n",
    "    i = 0\n",
    "    res = \"\"\n",
    "    s = s+' '\n",
    "    while i < len(s) :\n",
    "        if (s[i] is ',' and s[i+1].isalpha()) or (s[i] is ',' and s[i-1].isalpha()):\n",
    "            temp = \" \"\n",
    "        elif (s[i] is '-' and s[i+1].isspace()) or (s[i] is '-' and s[i-1].isspace()):\n",
    "            temp = \" \"\n",
    "        elif (s[i] is '.' and s[i+1].isalpha()) or (s[i] is '.' and s[i-1].isalpha()):\n",
    "            temp = \" \"\n",
    "        else:\n",
    "            temp = s[i]\n",
    "        res = res+temp\n",
    "        i+=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortFor(s):\n",
    "    result = []\n",
    "    spl = s.split()\n",
    "    for it in spl:\n",
    "        if it.lower() == 'mg':\n",
    "            it = 'miligram'\n",
    "        elif it.lower() == 'ml':\n",
    "            it = 'mililiter'\n",
    "        elif it.lower() == 'mcg':\n",
    "            it = 'mikrogram'\n",
    "        elif it.lower() == 'gr':\n",
    "            it = 'gram'\n",
    "        elif it.lower() == 'iu' or it.lower() == 'ui':\n",
    "            it = 'unit-internasional'\n",
    "        result.append(it)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_space(text):\n",
    "        \"\"\" Make extra space into one space. \"\"\"\n",
    "        text_list = text.split(' ')\n",
    "        text_list_temp = []\n",
    "\n",
    "        for word in text_list:\n",
    "            if word.strip():\n",
    "                text_list_temp.append(word.strip())\n",
    "\n",
    "        return ' '.join(text_list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSentence(s):\n",
    "    \"\"\"\n",
    "    sentences less than 4 words are removed\n",
    "    \"\"\"\n",
    "    co = s.split()\n",
    "    if len(co) > 3:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess2(s):\n",
    "    temp = removeSentence(remove_extra_space(shortFor(cleanPunct(s))))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = []\n",
    "temp = []\n",
    "restemp = []\n",
    "for item in flat_list:\n",
    "    temp.append(splitSentence(item))\n",
    "    \n",
    "restemp = [item for sublist in temp for item in sublist]\n",
    "for item in restemp:\n",
    "    res2.append(preprocess2(item))\n",
    "    \n",
    "res2 = list(filter(None, res2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17034"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from itertools import zip_longest\n",
    "d = [res2]\n",
    "export_data = zip_longest(*d, fillvalue = '')\n",
    "with open('Data_Preprocessed.csv', 'w', encoding=\"utf-8\", newline='') as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerow(([\"Data_Preprocessed\"]))\n",
    "    wr.writerows(export_data)\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FREQUENT WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add = []\n",
    "# for i in res2:\n",
    "#     split_it = i.split()   \n",
    "#     add.append(split_it) \n",
    "    \n",
    "# flat_list = [item for sublist in add for item in sublist]\n",
    "# Counter = Counter(flat_list) \n",
    "# most_occur = Counter.most_common(600) \n",
    "  \n",
    "# pd.set_option('display.max_rows',None)\n",
    "# # Calling DataFrame constructor on list \n",
    "# df = pd.DataFrame(most_occur) \n",
    "# li = []\n",
    "# for i in most_occur:\n",
    "#     if not i[0].isnumeric():\n",
    "#         li.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stopword(s):\n",
    "    read = pd.read_csv('Stopword_NER.csv')\n",
    "    more_stopword = read['Stopword'].tolist()\n",
    "    temp = []\n",
    "    for i in s.split():\n",
    "        if i.lower() not in more_stopword:\n",
    "            temp.append(i)\n",
    "    return ' '.join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = []\n",
    "count = 0\n",
    "for item in fix:\n",
    "    count +=1\n",
    "    res3.append(Stopword(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17844"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data_Preprocessed.csv\")\n",
    "df['Stopword'] = res3\n",
    "df.to_csv('Data_Preprocessed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
